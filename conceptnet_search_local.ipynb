{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from itertools import repeat\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import conceptnet_lite\n",
    "from conceptnet_lite import Label, edges_between, edges_for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConceptNet Local Search\n",
    "\n",
    "[Git Repo](https://github.com/ldtoolkit/conceptnet-lite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Code here in desprate need of refactoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CACHING (!!! execute this cell only once !!!)\n",
    "#\n",
    "\n",
    "node_cache_1 = {}\n",
    "node_cache_2 = {}\n",
    "\n",
    "rel_cache = {}\n",
    "\n",
    "#\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Globals\n",
    "#\n",
    "src = 'input/fRAT.csv'# for normal search 'input/embedding/fRAT_3.csv'\n",
    "rat_frat = 'frat'\n",
    "check = '2'\n",
    "path_depth = 1\n",
    "embedding_template = False\n",
    "\n",
    "templates_ending = {\n",
    "    'used_for': [('you can use', 'to'), ('you can use', 'for')],\n",
    "    'at_location': [('you are likely to find', 'in')],\n",
    "    'causes': [('the effect of', 'is')],\n",
    "    'has_subevent': [('something you might do while', 'is')],\n",
    "    'distinct_from': [('it cannot be both', 'and')],\n",
    "    'etymologically_related_to': [('the word', 'has the same origin as the word')]\n",
    "}\n",
    "\n",
    "templates_between = {\n",
    "    'related_to': ['is like', 'is related to'],\n",
    "    'is_a': ['is', 'is a'],\n",
    "    'part_of': ['is a part of'],\n",
    "    'used_for': ['is used to'],\n",
    "    'capable_of': ['can'],\n",
    "    'desires': ['wants'],\n",
    "    'synonym': ['has a similar meaning to'],\n",
    "    'antonym': ['is the opposite of'],\n",
    "    'causes_desires': ['makes people want'],\n",
    "}\n",
    "#\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nodes_frat(node, depth=1):\n",
    "    \"\"\" Given a node, get all the other nodes related to it\n",
    "        The search is performed by looking at all the edges related to a particular node.\n",
    "\n",
    "        Returns:\n",
    "            dictionary of form:\n",
    "                {\"pick_someone's_brain\": ['related_to'], 'blindly': ['related_to'], ...  'cross_purpose': ['related_to']}\n",
    "    \"\"\"\n",
    "    if depth == 1:\n",
    "        if node in node_cache_1.keys():\n",
    "            return node_cache_1[node]\n",
    "    elif depth == 2:\n",
    "        if node in node_cache_2.keys():\n",
    "            return node_cache_2[node]\n",
    "    \n",
    "    try:\n",
    "        # edges starting from (our node)\n",
    "        if node in node_cache_1.keys():\n",
    "            nodes = node_cache_1[node]\n",
    "        else:\n",
    "            nodes = []\n",
    "            for e in edges_for(Label.get(text=node, language='en').concepts, same_language=True):\n",
    "                if e.start.text not in [node]:\n",
    "                    nodes.append((e.start.text, e.relation.name))\n",
    "                if e.end.text not in [node]:\n",
    "                    nodes.append((e.end.text, e.relation.name))\n",
    "\n",
    "        if depth == 2:\n",
    "            nodes2 = []\n",
    "            for n in nodes.keys():\n",
    "                for e in edges_for(Label.get(text=n, language='en').concepts, same_language=True):\n",
    "                    if e.start.text not in [n]:\n",
    "                        nodes2.append((e.start.text, e.relation.name))\n",
    "                    if e.end.text not in [n]:\n",
    "                        nodes2.append((e.end.text, e.relation.name))\n",
    "\n",
    "        result = {}\n",
    "        for tup in list(set(nodes if depth == 1 else nodes2)):\n",
    "            if tup[0] not in result:\n",
    "                result[tup[0]] = list()\n",
    "                result[tup[0]].append(tup[1])\n",
    "            else:\n",
    "                result[tup[0]].append(tup[1])\n",
    "        \n",
    "        if depth == 1:\n",
    "            node_cache_1[node] = result  \n",
    "        else:\n",
    "            node_cache_2[node] = result\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        msg = '!!!   No label for the node \"{}\"... Are you sure the spelling is correct?'.format(node)\n",
    "        print(msg, e)\n",
    "        return {}\n",
    "\n",
    "# Depth 2 not implemented for RAT\n",
    "# Templates not implemented for RAT\n",
    "def get_nodes_rat(word):\n",
    "    \"\"\" Given a word, get all the compound words related to it as well as their relation name\n",
    "        Compound words are basically being identified by the underscore (_)\n",
    "    \"\"\"\n",
    "    # TODO: refactor the logic to be like frat\n",
    "    try:\n",
    "        result = []\n",
    "        relation = []\n",
    "        for e in edges_for(Label.get(text=word).concepts, same_language=True):\n",
    "            if (e.start.text.find('_') != -1) & (e.start.text.find(word) != -1):\n",
    "                result.append(e.start.text.replace(word, '').strip('_'))\n",
    "                relation.append(e.relation.name)\n",
    "            if (e.end.text.find('_') != -1) & (e.end.text.find(word) != -1):\n",
    "                result.append(e.end.text.replace(word, '').strip('_'))\n",
    "                relation.append(e.relation.name)\n",
    "\n",
    "        joint_result = []\n",
    "        for i in range(len(result)):\n",
    "            if result[i].find('_') != -1:\n",
    "                words = result[i].split('_')\n",
    "                for word in words:\n",
    "                    if word != '':\n",
    "                        joint_result.append((word, relation[i]))\n",
    "            else:\n",
    "                joint_result.append((result[i], relation[i]))\n",
    "\n",
    "        final_result = {}\n",
    "        for tup in list(set(joint_result)):\n",
    "            if tup[0] not in final_result:\n",
    "                final_result[tup[0]] = list()\n",
    "                final_result[tup[0]].append(tup[1])\n",
    "            else:\n",
    "                final_result[tup[0]].append(tup[1])\n",
    "        return final_result\n",
    "    except Exception as e:\n",
    "        msg = '!!!   No label for the node \"{}\"... Are you sure the spelling is correct?'.format(node)\n",
    "        print(msg, e)\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conceptnet():\n",
    "    conceptnet_lite.connect('conceptnet_database.db')\n",
    "\n",
    "def save_csv(rat_frat, check, output):\n",
    "    output = pd.DataFrame(list(output))\n",
    "    f_name = rat_frat + '_' + str(check) + '_conceptnet_search.xlsx'\n",
    "    dIr = os.path.join('output', rat_frat)\n",
    "    if not os.path.exists(dIr):\n",
    "        os.mkdir(dIr)\n",
    "    output.to_excel(os.path.join(dIr, f_name), index=False)\n",
    "    print('Saved results in {}'.format(f_name))\n",
    "    \n",
    "def check_for(relation_dict, check_for, query):\n",
    "    results = [set(relation_dict[key].keys()) for key in relation_dict.keys()]\n",
    "    \n",
    "    if (len(query) == 2) & ('2' in check_for):\n",
    "        yield results[0] & results[1], [query[0], query[1]]\n",
    "    \n",
    "    if (len(query) == 3) & ('2' in check_for):\n",
    "        yield results[0] & results[1], [query[0], query[1]]\n",
    "        yield results[0] & results[2], [query[0], query[2]]\n",
    "        yield results[1] & results[2], [query[1], query[2]]\n",
    "    \n",
    "    if (len(query) == 3) & ('3' in check_for):\n",
    "        yield results[0] & results[1] & results[2], [query[0], query[1], query[2]]\n",
    "    \n",
    "\n",
    "def get_output_normal(solutions, query, relation_dict, ground_solution, \n",
    "                      has_solution, triple_accuracy_flag):\n",
    "    \"\"\" Get the primary conceptnet output.\n",
    "        Relations are defined between the input triples & their ground_solutions.\n",
    "        Bidirectional as well as both solo directions are checked.\"\"\"\n",
    "    solutions = list(solutions)    \n",
    "    relations = [] # both directions\n",
    "    to_solution = [] # node -> solution\n",
    "    from_solution = [] # solution -> node\n",
    "    \n",
    "    # build a relationship message for: (1) node, (2) relation (3) solution\n",
    "    # For example:\n",
    "    #\n",
    "    # cues: antlers, doe, fawn\n",
    "    # relation: related_to\n",
    "    # solution: deer\n",
    "    # relationship message: antler is related_to deer, doe is related_to to deer, fawn is related_to to deer\n",
    "    if has_solution:\n",
    "        for node in query:\n",
    "            for sol in solutions:\n",
    "                rel = ', '.join(relation_dict[node][sol.strip()]) # get the relationships for each node and solution\n",
    "                relations.append(node + ' is \"'+ rel + '\" to ' + sol)\n",
    "\n",
    "                key = node + ' - ' + sol\n",
    "                if key in rel_cache.keys():\n",
    "                    for r in rel_cache[key]:\n",
    "                        from_solution.append(r)\n",
    "                else:\n",
    "                    rel_cache[key] = []                \n",
    "                    for e in edges_between(Label.get(text=node, language='en').concepts, Label.get(text=sol, language='en').concepts):\n",
    "                        rel = e.start.text + ' is \"' + e.relation.name + '\" to ' + e.end.text\n",
    "                        to_solution.append(rel)\n",
    "                        rel_cache[key].append(rel)\n",
    "\n",
    "        for sol in solutions:\n",
    "            for node in query:\n",
    "                key = sol + ' - ' + node\n",
    "                if key in rel_cache.keys():\n",
    "                    for r in rel_cache[key]:\n",
    "                        from_solution.append(r)\n",
    "                else:\n",
    "                    rel_cache[key] = []                \n",
    "                    for e in edges_between(Label.get(text=sol, language='en').concepts, Label.get(text=node, language='en').concepts):\n",
    "                        rel = e.start.text + ' is \"' + e.relation.name + '\" to ' + e.end.text\n",
    "                        from_solution.append(rel)\n",
    "                        rel_cache[key].append(rel)\n",
    "\n",
    "    return {'FrAt': ', '.join(query),\n",
    "            'ground solution': ground_solution,\n",
    "            'solutions': ', '.join(solutions),\n",
    "            'has_solution': has_solution,\n",
    "            'has_solution_tuple': triple_accuracy_flag,\n",
    "            'relation': ' | '.join(relations),\n",
    "            'relation_to_solution': ' | '.join(to_solution),\n",
    "            'relation_from_solution': ' | '.join(from_solution)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_embedding_template(solutions, query, relation_dict, ground_solution, \n",
    "                                  has_solution, triple_accuracy_flag):\n",
    "    \"\"\" Get the conceptnet output for connections between triples and the top embedding \n",
    "        (rather than from the ground_solution). \n",
    "        Moreover, relationships are split according to a pre-defined template.\n",
    "        Bi-directional.\"\"\"\n",
    "    \n",
    "    solutions = list(solutions)    \n",
    "    relations = [] # both directions\n",
    "    templates = {k: [] for k in {**templates_between,  **templates_ending}.keys()}\n",
    "    \n",
    "    # build a relationship message for: (1) node, (2) relation (3) solution\n",
    "    # For example:\n",
    "    #\n",
    "    # cues: antlers, doe, fawn\n",
    "    # relation: related_to\n",
    "    # solution: deer\n",
    "    # relationship message: antler is related_to deer, doe is related_to to deer, fawn is related_to to deer\n",
    "    if has_solution:\n",
    "        \n",
    "        for node in query:\n",
    "#             for sol in solutions: # ! can replace with solutions ggf.\n",
    "\n",
    "            # template relationships\n",
    "            for rel in relation_dict[node][ground_solution.strip()]:\n",
    "                if rel in templates_between.keys():\n",
    "                    for template in templates_between[rel]:\n",
    "                        templates[rel].append(f'{node} {template} {ground_solution}')\n",
    "                        templates[rel].append(f'{ground_solution} {template} {node}')\n",
    "                if rel in templates_ending.keys():\n",
    "                    for template in templates_ending[rel]:\n",
    "                        templates[rel].append(f'{template[0]} {node} {template[1]} {ground_solution}')\n",
    "                        templates[rel].append(f'{template[0]} {ground_solution} {template[1]} {node}')\n",
    "\n",
    "            # general relationship: get the relationships for each node and solution\n",
    "            rel = ', '.join(relation_dict[node][ground_solution.strip()])\n",
    "            for remove in ['related_to,', 'is_a,', 'is_a', 'related_to']:\n",
    "                rel = rel.replace(remove, '')\n",
    "            relations.append(node + ' is \"'+ rel + '\" to ' + ground_solution)\n",
    "\n",
    "\n",
    "    result = {'FrAt': ', '.join(query),\n",
    "            'top embedding': ground_solution,\n",
    "            'solutions': ', '.join(solutions),\n",
    "            'has_solution': has_solution,\n",
    "            'has_solution_tuple': triple_accuracy_flag,\n",
    "            'relation': ' | '.join(relations)}\n",
    "    for template in templates.keys():\n",
    "        result[template] = ' | '.join(templates[template])\n",
    "\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute(items):\n",
    "    index, query, df, args, output, accuracy = items\n",
    "    get_nodes = get_nodes_rat if args[0] == 'rat' else get_nodes_frat\n",
    "    ground_solution = df.iloc[index].wans if not embedding_template else df.iloc[index].embedding\n",
    "    get_output = get_output_normal if not embedding_template else get_output_embedding_template\n",
    "    relation_dict = {}\n",
    "    \n",
    "    for node in query:\n",
    "        relation_dict[node] = get_nodes(node)\n",
    "    \n",
    "    # the format of the relation_dict at this point would be\n",
    "    #\n",
    "    # { 'query_node': {'related_node_1': ['relation_1', 'relation_2'], ..., 'related_node_n': ['relation_1']}\n",
    "    #  'question': {\"pick_someone's_brain\": ['related_to'], 'blindly': ['related_to'], ... 'cross_purpose': ['related_to']},\n",
    "    #  'reply': {'repone': ['related_to'], ... 'sentences': ['related_to']},\n",
    "    #  'solution': {'solutionism': ['derived_from', 'related_to'],... 'exhibit': ['related_to']}\n",
    "    # }\n",
    "    \n",
    "    # only count once as TP if the triple or tuples are true\n",
    "    triple_accuracy_flag = False \n",
    "    checked = []\n",
    "    for result, quer in check_for(relation_dict, args[1], query):\n",
    "        print('Checking triple {}...'.format(quer))\n",
    "        print(quer)\n",
    "        if len(quer) == 3:\n",
    "            accuracy['total'] += 1\n",
    "        has_solution = any(str(ground_solution).lower().strip() == node for node in result)\n",
    "        \n",
    "        if has_solution:\n",
    "            triple_accuracy_flag = True\n",
    "            checked.append(quer)\n",
    "            output.append(get_output(result, quer, relation_dict, ground_solution, \n",
    "                                    has_solution, triple_accuracy_flag))\n",
    "        \n",
    "        elif(path_depth == 2):\n",
    "            relation_dict2 = {}\n",
    "            print('Checking depth 2 for triple {}...'.format(quer))\n",
    "            for node in quer:\n",
    "                relation_dict2[node] = get_nodes(node, 2)\n",
    "            for result2, quer2 in check_for(relation_dict2, args[1], quer):\n",
    "                if any((quer2 == q for q in checked)):\n",
    "                    continue\n",
    "                \n",
    "                checked.append(quer2)\n",
    "                has_solution = any(ground_solution.lower().strip() == node for node in result2)\n",
    "                if has_solution:\n",
    "                    accuracy['tp'] += 1\n",
    "                    triple_accuracy_flag = True\n",
    "                        \n",
    "                output.append(get_output(result2, quer2, relation_dict2, ground_solution, \n",
    "                                         has_solution, triple_accuracy_flag))\n",
    "        \n",
    "        else:\n",
    "            output.append(get_output(result, quer, relation_dict, ground_solution, \n",
    "                                     has_solution, triple_accuracy_flag))\n",
    "    \n",
    "    if triple_accuracy_flag:\n",
    "        accuracy['tp'] += 1\n",
    "                        \n",
    "    return output, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking triple ['question', 'reply', 'solution']...\n",
      "['question', 'reply', 'solution']\n",
      "Checking triple ['sensitive', 'sob', 'weep']...\n",
      "['sensitive', 'sob', 'weep']\n",
      "Checking triple ['antlers', 'doe', 'fawn']...\n",
      "['antlers', 'doe', 'fawn']\n",
      "Checking triple ['bud', 'dandelion', 'petals']...\n",
      "['bud', 'dandelion', 'petals']\n",
      "Checking triple ['colt', 'mare', 'unicorn']...\n",
      "['colt', 'mare', 'unicorn']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:03,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!   No label for the node \"royaly\"... Are you sure the spelling is correct? <Model: Label> instance matching query does not exist:\n",
      "SQL: SELECT \"t1\".\"id\", \"t1\".\"text\", \"t1\".\"language_id\" FROM \"label\" AS \"t1\" WHERE ((\"t1\".\"language_id\" = ?) AND (\"t1\".\"text\" = ?)) LIMIT ? OFFSET ?\n",
      "Params: [30, 'royaly', 1, 0]\n",
      "Checking triple ['crown', 'royaly', 'throne']...\n",
      "['crown', 'royaly', 'throne']\n",
      "Checking triple ['algebra', 'calculus', 'trigonometry']...\n",
      "['algebra', 'calculus', 'trigonometry']\n",
      "Checking triple ['pedal', 'pull', 'shove']...\n",
      "['pedal', 'pull', 'shove']\n",
      "Checking triple ['clockwise', 'left', 'wrong']...\n",
      "['clockwise', 'left', 'wrong']\n",
      "Checking triple ['flu', 'nauseous', 'virus']...\n",
      "['flu', 'nauseous', 'virus']\n",
      "Checking triple ['astronomy', 'moon', 'twinkle']...\n",
      "['astronomy', 'moon', 'twinkle']\n",
      "Checking triple ['bait', 'pond', 'tuna']...\n",
      "['bait', 'pond', 'tuna']\n",
      "Checking triple ['bandaid', 'trim', 'wound']...\n",
      "['bandaid', 'trim', 'wound']\n",
      "Checking triple ['gravity', 'low', 'up']...\n",
      "['gravity', 'low', 'up']\n",
      "Checking triple ['emergency', 'rapid', 'slow']...\n",
      "['emergency', 'rapid', 'slow']\n",
      "Checking triple ['brawl', 'debate', 'soldier']...\n",
      "['brawl', 'debate', 'soldier']\n",
      "Checking triple ['birds', 'frog', 'kite']...\n",
      "['birds', 'frog', 'kite']\n",
      "Checking triple ['finger', 'glove', 'palm']...\n",
      "['finger', 'glove', 'palm']\n",
      "Checking triple ['bed', 'darkness', 'sedative']...\n",
      "['bed', 'darkness', 'sedative']\n",
      "Checking triple ['discuss', 'gossip', 'telephone']...\n",
      "['discuss', 'gossip', 'telephone']\n",
      "Checking triple ['fangs', 'gums', 'wolf']...\n",
      "['fangs', 'gums', 'wolf']\n",
      "Checking triple ['marsh', 'saliva', 'slippery']...\n",
      "['marsh', 'saliva', 'slippery']\n",
      "Checking triple ['dictionary', 'verse', 'vocabulary']...\n",
      "['dictionary', 'verse', 'vocabulary']\n",
      "Checking triple ['fault', 'incorrect', 'unjust']...\n",
      "['fault', 'incorrect', 'unjust']\n",
      "Checking triple ['murder', 'operate', 'vein']...\n",
      "['murder', 'operate', 'vein']\n",
      "Checking triple ['empire', 'moat', 'princess']...\n",
      "['empire', 'moat', 'princess']\n",
      "Checking triple ['bench', 'sofa', 'stool']...\n",
      "['bench', 'sofa', 'stool']\n",
      "Checking triple ['beaker', 'flask', 'science']...\n",
      "['beaker', 'flask', 'science']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [00:03, 14.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!   No label for the node \"yo-yo\"... Are you sure the spelling is correct? <Model: Label> instance matching query does not exist:\n",
      "SQL: SELECT \"t1\".\"id\", \"t1\".\"text\", \"t1\".\"language_id\" FROM \"label\" AS \"t1\" WHERE ((\"t1\".\"language_id\" = ?) AND (\"t1\".\"text\" = ?)) LIMIT ? OFFSET ?\n",
      "Params: [30, 'yo-yo', 1, 0]\n",
      "Checking triple ['adults', 'development', 'yo-yo']...\n",
      "['adults', 'development', 'yo-yo']\n",
      "Checking triple ['cemetery', 'coma', 'noose']...\n",
      "['cemetery', 'coma', 'noose']\n",
      "Checking triple ['exam', 'scare', 'terror']...\n",
      "['exam', 'scare', 'terror']\n",
      "Checking triple ['hand', 'toe', 'trigger']...\n",
      "['hand', 'toe', 'trigger']\n",
      "Checking triple ['angel', 'church', 'faith']...\n",
      "['angel', 'church', 'faith']\n",
      "Checking triple ['body', 'commander', 'skull']...\n",
      "['body', 'commander', 'skull']\n",
      "Checking triple ['cello', 'scalpel', 'trumpet']...\n",
      "['cello', 'scalpel', 'trumpet']\n",
      "Checking triple ['desk', 'quill', 'stapler']...\n",
      "['desk', 'quill', 'stapler']\n",
      "Checking triple ['arrest', 'badge', 'deputy']...\n",
      "['arrest', 'badge', 'deputy']\n",
      "Checking triple ['electron', 'inertia', 'zest']...\n",
      "['electron', 'inertia', 'zest']\n",
      "Checking triple ['diet', 'strain', 'sweat']...\n",
      "['diet', 'strain', 'sweat']\n",
      "Checking triple ['assault', 'cop', 'murder']...\n",
      "['assault', 'cop', 'murder']\n",
      "Checking triple ['drill', 'grave', 'spike']...\n",
      "['drill', 'grave', 'spike']\n",
      "Checking triple ['care', 'tactful', 'willing']...\n",
      "['care', 'tactful', 'willing']\n",
      "Checking triple ['midnight', 'saturn', 'wolf']...\n",
      "['midnight', 'saturn', 'wolf']\n",
      "Checking triple ['bloom', 'opportunity', 'split']...\n",
      "['bloom', 'opportunity', 'split']\n",
      "Checking triple ['accomplished', 'dolphin', 'sly']...\n",
      "['accomplished', 'dolphin', 'sly']\n",
      "Checking triple ['duck', 'sardine', 'sinker']...\n",
      "['duck', 'sardine', 'sinker']\n",
      "Checking triple ['europe', 'mushroom', 'pack']...\n",
      "['europe', 'mushroom', 'pack']\n",
      "Checking triple ['fierce', 'steel', 'warrior']...\n",
      "['fierce', 'steel', 'warrior']\n",
      "Saved results in frat_3_conceptnet_search.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "get_conceptnet()\n",
    "output = []\n",
    "accuracy = {\n",
    "    'total': 0,\n",
    "    'tp': 0\n",
    "}\n",
    "\n",
    "if rat_frat == 'rat': # rat|frat CSVs have different structure\n",
    "    df = pd.read_csv(src)\n",
    "elif rat_frat == 'frat':\n",
    "    df = pd.read_csv(src, sep=';')\n",
    "\n",
    "if embedding_template:\n",
    "    df = pd.read_csv(src, sep=';')\n",
    "\n",
    "queries = df.w1 + ' ' + df.w2 + ' ' + df.w3\n",
    "queries = [list(map(lambda x: x.lower(), filter(len, line.split(' ')))) for line in queries]\n",
    "\n",
    "# queries triples as list of list\n",
    "# [['question', 'reply', 'solution'], ... ['fault', 'incorrect', 'unjust']]\n",
    "for item in tqdm(zip(range(0, len(queries)),\n",
    "                queries,\n",
    "                repeat(df),\n",
    "                repeat((rat_frat, check)),\n",
    "                repeat(output),\n",
    "                repeat(accuracy))):\n",
    "    output, accuracy = compute(item)\n",
    "\n",
    "output.append({'Accuracy': str(round(100*accuracy['tp']/accuracy['total'], 2)) + '%'})\n",
    "save_csv(rat_frat, check, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy['tp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cached {} nodes in the first level, {} in the second and {} relationships'.format(\n",
    "        len(node_cache_1), len(node_cache_2), len(rel_cache)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

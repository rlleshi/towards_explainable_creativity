{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import itertools\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import conceptnet_lite\n",
    "from conceptnet_lite import Label, edges_between, edges_for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "rat = 'RAT.csv'\n",
    "frat = 'fRAT.csv'\n",
    "\n",
    "### set the csv file to examine\n",
    "csv = rat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************    CSV file set to \u001b[1m RAT \u001b[0;0m    ***************\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "      <th>w3</th>\n",
       "      <th>wans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cottage</td>\n",
       "      <td>Swiss</td>\n",
       "      <td>Cake</td>\n",
       "      <td>Cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cream</td>\n",
       "      <td>Skate</td>\n",
       "      <td>Water</td>\n",
       "      <td>Ice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Loser</td>\n",
       "      <td>Throat</td>\n",
       "      <td>Spot</td>\n",
       "      <td>Sore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Show</td>\n",
       "      <td>Life</td>\n",
       "      <td>Row</td>\n",
       "      <td>Boat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Night</td>\n",
       "      <td>Wrist</td>\n",
       "      <td>Stop</td>\n",
       "      <td>Watch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        w1      w2     w3     wans\n",
       "0  Cottage   Swiss   Cake  Cheese \n",
       "1    Cream   Skate  Water     Ice \n",
       "2    Loser  Throat   Spot    Sore \n",
       "3     Show    Life    Row    Boat \n",
       "4    Night   Wrist   Stop   Watch "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if csv == rat:\n",
    "    # in csv format\n",
    "    df = pd.read_csv(os.path.join('input', csv))\n",
    "else: \n",
    "    df = pd.read_csv(os.path.join('input', csv), sep=';')\n",
    "\n",
    "conceptnet_lite.connect(r\"C:\\Users\\rejna\\Work_only_here\\Miscellaneous\\rakshitha\\conceptnet_database\")\n",
    "\n",
    "print('***************    CSV file set to \\033[1m {} \\033[0;0m    ***************'.format(csv[:-4]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df = pd.DataFrame(df.RAT.str.split(' ').tolist(),\n",
    "#                                  columns = ['w1','w2', 'w3', 'w4'])\n",
    "\n",
    "# new_df.w4 = df.Solutions\n",
    "# new_df.columns = ['w1', 'w2', 'w3', 'wans']\n",
    "# new_df.to_csv('rat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv(content, random=''):\n",
    "    output = pd.DataFrame(content)\n",
    "    file_output = csv.strip('.csv') + random + '_check_' + check_for.strip(',') + '_solution_' + str(t) + '.xlsx'\n",
    "    if not os.path.exists('output'):\n",
    "        os.mkdir('output')\n",
    "\n",
    "    output.to_excel(os.path.join('output', file_output), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FRAT & RAT\n",
    "## Local search implementation\n",
    "### Search for related nodes intersection (no compound words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "check_for = '2,3' # separate digits by comma, even if only 1\n",
    "t = True # whether or not the solution should be contained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nodes_frat(node):\n",
    "    \"\"\" Given a word, get all the words related to it\n",
    "    \n",
    "        Returns:\n",
    "            dictionary of form: \n",
    "                {\"pick_someone's_brain\": ['related_to'], 'blindly': ['related_to'], ...  'cross_purpose': ['related_to']}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # TODO: is there a problem with the relationship's direction here?\n",
    "        current = [(e.start.text, e.relation.name) \n",
    "                    for e in edges_for(Label.get(text=node, language='en').concepts, same_language=True) \n",
    "                       if e.start.text not in [node]]\n",
    "        [current.append((e.end.text, e.relation.name)) \n",
    "            for e in edges_for(Label.get(text=node, language='en').concepts, same_language=True)\n",
    "                   if e.end.text not in [node]]\n",
    "        \n",
    "        result = {}\n",
    "        for tup in list(set(current)): \n",
    "            if tup[0] not in result:\n",
    "                result[tup[0]] = list()\n",
    "                result[tup[0]].append(tup[1])\n",
    "            else:\n",
    "                result[tup[0]].append(tup[1])\n",
    "        return result\n",
    "    except Exception as error:\n",
    "        print('No label for the node \"{}\"... Are you sure the spelling is correct?'.format(node))\n",
    "        return {}\n",
    "\n",
    "def get_nodes_rat(word):\n",
    "    \"\"\" Given a word, get all the compound words related to it as well as their relation name \n",
    "        Compound words are basically being identified by the underscore (_)\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    relation = []\n",
    "    for e in edges_for(Label.get(text=word).concepts, same_language=True):\n",
    "        if (e.start.text.find('_') != -1) & (e.start.text.find(word) != -1):\n",
    "            result.append(e.start.text.replace(word, '').strip('_'))\n",
    "            relation.append(e.relation.name)\n",
    "        if (e.end.text.find('_') != -1) & (e.end.text.find(word) != -1):\n",
    "            result.append(e.end.text.replace(word, '').strip('_'))\n",
    "            relation.append(e.relation.name)\n",
    "\n",
    "    joint_result = []\n",
    "    for i in range(len(result)):\n",
    "        if result[i].find('_') != -1:\n",
    "            words = result[i].split('_')\n",
    "            for word in words:\n",
    "                if word != '': joint_result.append((word, relation[i]))\n",
    "        else:\n",
    "            joint_result.append((result[i], relation[i]))\n",
    "    \n",
    "#     return joint_result\n",
    "       \n",
    "    final_result = {}\n",
    "    for tup in list(set(joint_result)): \n",
    "        if tup[0] not in final_result:\n",
    "            final_result[tup[0]] = list()\n",
    "            final_result[tup[0]].append(tup[1])\n",
    "        else:\n",
    "            final_result[tup[0]].append(tup[1])\n",
    "    return final_result\n",
    "    # words can still be compounded, so we split them and merge the lists\n",
    "#     return list(itertools.chain(*[filter(len, word.split('_')) for word in result])), relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checker(relation_dict, check_for, cue):\n",
    "    results = [set(relation_dict[key].keys()) for key in relation_dict.keys()]\n",
    "\n",
    "    if '3' in check_for:\n",
    "        yield results[0] & results[1] & results[2], relation_dict, [cue[0], cue[1], cue[2]]\n",
    "    if '2' in check_for:\n",
    "        yield results[0] & results[1], relation_dict, [cue[0], cue[1]]\n",
    "        yield results[0] & results[2], relation_dict, [cue[0], cue[2]]\n",
    "        yield results[1] & results[2], relation_dict, [cue[1], cue[2]]\n",
    "\n",
    "def get_output(result, cues, relation_dict, solution, has_solution):\n",
    "    solutions = [res for res in result] if result else []\n",
    "    relations = list()\n",
    "    \n",
    "    # build a relationship message for each (1) node, (2) relation (3) solution\n",
    "    # For example:\n",
    "    #\n",
    "    # cues: antlers, doe, fawn\n",
    "    # relation: related_to\n",
    "    # solution: deer\n",
    "    # relationship message: antler is related_to deer, doe is related_to to deer, fawn is related_to to deer\n",
    "    for cue in cues:\n",
    "        for sol in solutions:\n",
    "            rel = ', '.join(relation_dict[cue][sol.strip()]) # get the relationships for each cue and solution\n",
    "            relations.append(cue + ' is \"'+ rel + '\" to ' + sol)\n",
    "        \n",
    "    return {'FrAt': ', '.join(cues), \n",
    "            'ground solution': solution,\n",
    "            'solutions': ', '.join(solutions),\n",
    "            'has_solution': has_solution,\n",
    "            'relation': ' | '.join(relations)\n",
    "           } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished ['cottage', 'swiss', 'cake']. Timestamp: 0.0 min\n",
      "Finished ['cream', 'skate', 'water']. Timestamp: 0.04 min\n",
      "Finished ['loser', 'throat', 'spot']. Timestamp: 0.12 min\n",
      "Finished ['show', 'life', 'row']. Timestamp: 0.15 min\n"
     ]
    }
   ],
   "source": [
    "concat = df.w1 + ' ' + df.w2 + ' ' + df.w3\n",
    "concat = concat[:-1] # remove last nan element\n",
    "cues = [list(map(lambda x: x.lower(), filter(len, line.split(' ')))) for line in concat]\n",
    "get_nodes = get_nodes_rat if csv == rat else get_nodes_frat\n",
    "start_time = time.time()\n",
    "output = []\n",
    "index = 0\n",
    "total = 0\n",
    "tp = 0\n",
    "\n",
    "for cue in cues:\n",
    "    results = {}\n",
    "    solution = df.iloc[index].wans\n",
    "    index +=1 \n",
    "    print('Finished {}. Timestamp: {} min'.format(cue, round((time.time()-start_time)/60, 2)))\n",
    "\n",
    "    for c in cue:\n",
    "        results[c] = get_nodes(c)\n",
    "    \n",
    "    # so the format of the results dictionary at this point would be \n",
    "    #\n",
    "    # {'question': {\"pick_someone's_brain\": ['related_to'], 'blindly': ['related_to'], ... 'cross_purpose': ['related_to']},  \n",
    "    # 'reply': {'repone': ['related_to'], ... 'sentences': ['related_to']}, \n",
    "    # 'solution': {'solutionism': ['derived_from', 'related_to'],... 'exhibit': ['related_to']}}\n",
    "\n",
    "    for result, relation_dict, cue in checker(results, check_for, cue):\n",
    "        total += 1\n",
    "        has_solution = any(solution.lower().strip() in res for res in result)\n",
    "\n",
    "        if has_solution: tp+=1\n",
    "        \n",
    "        output.append(get_output(result, cue, relation_dict, solution, has_solution))\n",
    "\n",
    "\n",
    "# save\n",
    "output.append({'Accuracy': str(round(100*tp/total, 2)) + '%'})\n",
    "save_csv(output, '_new_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
